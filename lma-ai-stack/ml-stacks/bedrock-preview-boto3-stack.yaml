AWSTemplateFormatVersion: "2010-09-09"

Description: Lambda Layer for boto3 Amazon Bedrock SDK extensions.

Resources:

  BedrockBoto3Bucket:
    Type: AWS::S3::Bucket
    Metadata:
      cfn_nag:
        rules_to_suppress:
        - id: W51
          reason: Bucket has identity based policy.
    # checkov:skip=CKV_AWS_18: "Access logging configured via LoggingConfiguration property"
    # checkov:skip=CKV_AWS_53: "Public access is blocked via PublicAccessBlockConfiguration"
    # checkov:skip=CKV_AWS_54: "Public access is blocked via PublicAccessBlockConfiguration"
    # checkov:skip=CKV_AWS_55: "Public access is blocked via PublicAccessBlockConfiguration"
    # checkov:skip=CKV_AWS_56: "Public access is blocked via PublicAccessBlockConfiguration"
    # checkov:skip=CKV_AWS_21: "Versioning enabled via VersioningConfiguration"
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
        - ServerSideEncryptionByDefault:
            SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      LoggingConfiguration:
        DestinationBucketName: !Ref LoggingBucketName
        LogFilePrefix: "bedrock-boto3-bucket-logs/"

  BedrockBoto3ZipFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: lambda.amazonaws.com
          Action: sts:AssumeRole
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      PermissionsBoundary: !Ref PermissionsBoundaryArn
      Policies:
      - PolicyDocument:
          Version: 2012-10-17
          Statement:
          - Effect: Allow
            Action:
            - 's3:PutObject'
            - 's3:DeleteObject'
            - 's3:ListBucket'
            Resource: !Sub 'arn:aws:s3:::${BedrockBoto3Bucket}*'
        PolicyName: S3Policy

  BedrockBoto3ZipFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Runtime: python3.12
      Role: !GetAtt 'BedrockBoto3ZipFunctionRole.Arn'
      Timeout: 60
      MemorySize: 512
      Environment:
        Variables:
          BOTO3_BUCKET: !Ref BedrockBoto3Bucket
      Code:
        ZipFile: |
          import os
          import sys
          import re
          import shutil
          import subprocess
          import boto3
          import zipfile
          import urllib3
          import json
          from datetime import datetime
          import cfnresponse
          boto3_bucket = os.environ['BOTO3_BUCKET']

          def upload_file_to_s3(file_path, bucket, key):
              s3 = boto3.client('s3')
              s3.upload_file(file_path, bucket, key)
              print(f"Upload successful. {file_path} uploaded to {bucket}/{key}")

          def make_zip_filename():
            now = datetime.now()
            timestamp = now.strftime('%Y%m%d_%H%M%S')
            filename = f'BedrockBoto3SDK_{timestamp}.zip'
            return filename

          def zipdir(path, zipname):
            zipf = zipfile.ZipFile(zipname, 'w', zipfile.ZIP_DEFLATED)
            for root, dirs, files in os.walk(path):
                for file in files:
                    zipf.write(os.path.join(root, file),
                              os.path.relpath(os.path.join(root, file), 
                                              os.path.join(path, '..')))
            zipf.close()

          def deleteObject(existingZip):
              print(f'Deleting Existing Zip: {existingZip}')
              s3_client = boto3.client('s3')
              s3_client.delete_object(Bucket=existingZip["Bucket"], Key=existingZip["Key"])
              return

          def handler(event, context):
            print("Event: ", json.dumps(event))
            physicalResourceId = event.get("PhysicalResourceId", None)
            existingZip = None
            if physicalResourceId:
              try:
                existingZip = json.loads(physicalResourceId)
              except:
                existingZip = ""
            responseData={}
            reason=""
            status = cfnresponse.SUCCESS
            try: 
              if event['RequestType'] != 'Delete':
                os.chdir('/tmp')
                print(f"running pip install boto3==1.36.19")
                subprocess.check_call([sys.executable, "-m", "pip", "install", "boto3==1.36.19", "-t", "python" ])
                boto3_zip_name = make_zip_filename()
                zipdir("python",boto3_zip_name)
                print(f"uploading {boto3_zip_name} to s3 bucket {boto3_bucket}")
                upload_file_to_s3(boto3_zip_name, boto3_bucket, boto3_zip_name)
                responseData = {"Bucket": boto3_bucket, "Key": boto3_zip_name}
                physicalResourceId = json.dumps(responseData)
              else:
                print(f"RequestType is: {event['RequestType']}")
            except Exception as e:
              print(e)
              status = cfnresponse.FAILED
              reason = f"Exception thrown: {e}"
            # delete any previously created zip file (during update or delete), so that bucket can be deleted
            if existingZip:
              deleteObject(existingZip)
            cfnresponse.send(event, context, status, responseData, reason=reason, physicalResourceId=physicalResourceId)
      LoggingConfig:
        LogGroup:
          Fn::Sub: /${AWS::StackName}/lambda/BedrockBoto3ZipFunction
    Metadata:
      cfn_nag:
        rules_to_suppress:
        - id: W89
          reason: Lambda function is not communicating with any VPC resources.
        - id: W92
          reason: No requirements to set reserved concurrencies, function will not
            be invoked simultaneously.
    # checkov:skip=CKV_AWS_115: "Function does not require reserved concurrency as it scales based on demand"
    # checkov:skip=CKV_AWS_116: "DLQ not required for Cfn Custom Resource function"
    # checkov:skip=CKV_AWS_117: "Function does not require VPC access as it only interacts with AWS services via APIs"
    # checkov:skip=CKV_AWS_173: "Environment variables do not contain sensitive data - only configuration values like feature flags and non-sensitive settings"
    DependsOn:
    - BedrockBoto3ZipFunctionLogGroup

  BedrockBoto3ZipFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName:
        Fn::Sub: /${AWS::StackName}/lambda/BedrockBoto3ZipFunction
      RetentionInDays:
        Ref: CloudWatchLogsExpirationInDays
      KmsKeyId: !Ref CustomerManagedEncryptionKeyArn

  BedrockBoto3Zip:
    Type: Custom::BedrockBoto3Zip
    Properties:
      ServiceToken: !GetAtt BedrockBoto3ZipFunction.Arn
      # Rerun BedrockBoto3ZipFunction if any of the following parameters change
      BOTO3_BUCKET: !Ref BedrockBoto3Bucket
      VERSION: 1

  BedrockBoto3Layer:
    Type: "AWS::Lambda::LayerVersion"
    Properties:
      Content:
        S3Bucket: !GetAtt BedrockBoto3Zip.Bucket
        S3Key: !GetAtt BedrockBoto3Zip.Key
      CompatibleRuntimes:
      - python3.12

Outputs:

  BedrockBoto3Layer:
    Description: Lambda layer for Boto3 Bedrock SDK extensions
    Value: !Ref BedrockBoto3Layer

Parameters:
  CloudWatchLogsExpirationInDays:
    Type: Number
    Default: 14
    Description: The number of days log events are kept in CloudWatch Logs.

  CustomerManagedEncryptionKeyArn:
    Type: String
    Description: ARN of the customer managed KMS key for encryption

  LoggingBucketName:
    Type: String
    Description: Name of the logging bucket for S3 access logs
    # Important: When deploying this template, provide an explicit bucket name
    # Example: my-secure-logging-bucket

  PermissionsBoundaryArn:
    Type: String
    Default: AWS::NoValue
    Description: >-
      (Optional) ARN of an existing IAM managed policy to use as permissions boundary for IAM roles.
      If provided, this policy will limit the maximum permissions that can be granted to IAM roles
      in this stack, providing an additional layer of security.
